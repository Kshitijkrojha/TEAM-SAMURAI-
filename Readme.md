United Airlines SkyHack: A Data-Driven Framework for Proactive Operations
Team: Team Samurai
Date: October 5, 2025

Tech Stack
This project leverages a modern, open-source data science stack:

🐍 Python: The core programming language for all analysis and scripting.

🐼 Pandas: For data manipulation, cleaning, and aggregation.

📊 Matplotlib & Seaborn: For static data visualization and generating charts for the reports.

🤖 Scikit-learn: For building and evaluating the predictive machine learning model.

📓 Jupyter Notebooks: For iterative analysis, storytelling, and documenting the research process.

🎈 Streamlit: For building and deploying the interactive web dashboard.

1. Project Overview
This project addresses the United Airlines SkyHack challenge to develop a systematic framework for identifying and managing operationally complex flights at Chicago O’Hare International Airport (ORD). Our solution moves beyond a simple analysis to deliver a complete, end-to-end operational toolkit designed for real-world implementation.

Our framework consists of:

A series of analytical notebooks that tell the story of our findings.

An automated Python data pipeline for reliable, repeatable analysis.

A daily Flight Difficulty Score that quantifies complexity.

An interactive dashboard prototype to deliver real-time insights to frontline managers.

The goal of this project is to empower United's operations teams to shift from a reactive to a proactive and predictive mindset, enabling optimized resource allocation and enhancing on-time performance.

2. Project Structure
This project is organized into a professional, modular structure to ensure clarity, maintainability, and ease of use.

Team Samurai/
│
├── README.md               # You are here!
│
├── notebooks/              # Contains the detailed, step-by-step analytical story.
│   ├── 0_Data_Preparation_and_Merging.ipynb
│   ├── 1_Exploratory_Data_Analysis.ipynb
│   ├── 2_Solution_Flight_Difficulty_Score.ipynb
│   ├── 3_Insights_and_Recommendations.ipynb
│   └── 4_Advanced_Analysis_Predictive_Modeling.ipynb
│
├── scripts/                # Contains the automated, production-ready Python pipeline.
│   ├── data_loader.py
│   ├── feature_engineering.py
│   ├── scoring.py
│   └── insights.py
│
├── main.py                 # Main script to run the entire automated pipeline.
├── dashboard.py            # The interactive Streamlit dashboard application.
│
├── presentation/           # Contains the final presentation slides.
│   └── Team_Samurai.pdf
│
├── data/                   # Contains the 5 raw input CSV files.
│
└── output/                 # Contains all generated data files.
    ├── processed_data/     # Intermediate, analysis-ready data.
    └── test_TeamSamurai.csv  # The final, scored CSV deliverable.

3. How to Run This Project
Environment Setup
It is recommended to use a virtual environment. The required libraries can be installed via pip:

pip install pandas numpy matplotlib seaborn scikit-learn streamlit

Option 1: Explore the Analysis Step-by-Step (Recommended)
The analytical journey is best explored through the Jupyter Notebooks in the /notebooks folder. They should be run in numerical order.

0_Data_Preparation_and_Merging.ipynb: This must be run first. It loads all raw data and creates the primary analysis_ready_data.csv file needed by the other notebooks.

1_Exploratory_Data_Analysis.ipynb: Performs the EDA as required by Deliverable #1.

2_Solution_Flight_Difficulty_Score.ipynb: Calculates the final score and creates the final test_TeamSamurai.csv file.

3_Insights_and_Recommendations.ipynb: Generates the key business insights and recommendations.

4_Advanced_Analysis_Predictive_Modeling.ipynb: Builds and evaluates the predictive ML model.

Option 2: Run the Automated Pipeline
To run the entire data pipeline from start to finish with a single command and generate the final test_TeamSamurai.csv, navigate to the project's root directory in your terminal and execute:

python main.py

Option 3: Launch the Interactive Dashboard
Our solution includes an interactive dashboard prototype for frontline operational use. To launch it, ensure that test_TeamSamurai.csv has been generated by running either Notebook #2 or the main.py script.

Then, run the following command from the project's root directory:

streamlit run dashboard.py

This will open the dashboard in your web browser.

4. Key Findings & Recommendations
Our analysis successfully identified three key, data-proven operational problems:

The "Destination DNA" Problem: Different destinations are difficult for different reasons (e.g., passenger-driven complexity for MCO vs. operations-driven complexity for EWR).

The "Peak Pressure" Problem: Operational stress is predictably concentrated during the morning (7-9 AM) and evening (4-7 PM) rush hours.

The "High-Stakes Connection" Problem: Flights with high transfer bag counts and tight ground times are 2.5x more likely to be delayed.

Based on these findings, we recommend a three-pronged strategy of implementing destination-specific resource plans, deploying a peak-hour operations manager, and launching a proactive alert system for high-risk flights.
